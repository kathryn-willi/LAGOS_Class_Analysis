---
title: "Lake Water Quality Analysis"
author: "Matthew Ross (Kathryn Willi Submission)"
date: "9/17/2019"
output:
  html_document: default
  word_document: default
---



```{r setup, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
library(lubridate) #For dealing with date and time
```


# LAGOS Analysis


## Loading in data


### First download and then specifically grab the locus (or site lat longs)
```{r data-read}
#Lagos download script
#lagosne_get(dest_folder = LAGOSNE:::lagos_path(), overwrite = T)
#Load in lagos
lagos <- lagosne_load()
#Grab the lake centroid info
lake_centers <- lagos$locus
# Make an sf object 
spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326)
#Grab the water quality data
nutr <- lagos$epi_nutr
#Look at column names
#names(nutr)
```

### Subset columns nutr to only keep key info that we want


```{r, warning=FALSE}
clarity_only <- nutr %>%
  select(lagoslakeid,sampledate,chla,doc,secchi) %>%
  mutate(sampledate = as.character(sampledate) %>% ymd(.))
```


### Keep sites with at least 200 observations 

```{r}
#Look at the number of rows of dataset
nrow(clarity_only)
chla_secchi <- clarity_only %>%
  filter(!is.na(chla),
         !is.na(secchi))
# How many observatiosn did we lose?
nrow(clarity_only) - nrow(chla_secchi)
# Keep only the lakes with at least 200 observations of secchi and chla
chla_secchi_200 <- chla_secchi %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) %>%
  filter(count > 200)
```


### Join water quality data to spatial data

```{r}
spatial_200 <- inner_join(spatial_lakes,chla_secchi_200 %>%
                            distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid')
```

### Mean Chl_a map

```{r}
### Take the mean chl_a and secchi by lake
mean_values_200 <- chla_secchi_200 %>%
  # Take summary by lake id
  group_by(lagoslakeid) %>%
  # take mean chl_a per lake id
  summarize(mean_chl = mean(chla,na.rm=T),
            mean_secchi=mean(secchi,na.rm=T)) %>%
  #Get rid of NAs
  filter(!is.na(mean_chl),
         !is.na(mean_secchi)) %>%
  # Take the log base 10 of the mean_chl
  mutate(log10_mean_chl = log10(mean_chl))
#Join datasets
mean_spatial <- inner_join(spatial_lakes,mean_values_200,
                          by='lagoslakeid') 
#Make a map
mapview(mean_spatial,zcol='log10_mean_chl')
```


# Class work

## 1) What is the correlation between Secchi Disk Depth and Chlorophyll a for sites with at least 200 observations?

- Here, I just want a plot of chla vs secchi for all sites 

```{r}
#Your code here

ggplot(data=chla_secchi_200, aes(x=secchi, y=chla))+
  geom_point()

#OR

ggplot(mean_values_200, aes(x=mean_secchi, y=log10_mean_chl))+
  geom_point()

```


## Why might this be the case? 

Chlorophyll a 'foggies' up the water! 

## 2) What states have the most data? 

### 2a) First you will need to make a lagos spatial dataset that has the total number of counts per site.

```{r}
## Your code here

#total_samps_per_site <- clarity_only %>%
  #group_by(lagoslakeid)%>%
  #summarize(count=n())


#OR...

total_samps_per_site <- clarity_only %>%
  gather(Sample, Value, chla, doc, secchi, -lagoslakeid, -sampledate)%>%
  filter(!is.na(Value))%>%
  group_by(lagoslakeid)%>%
  summarize(count=n())


spatial_join <- inner_join(total_samps_per_site,lake_centers %>%
                            distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid') %>%
  st_as_sf(coords=c('nhd_long','nhd_lat'), crs=4326)

#mapview(spatial_join)

```


### 2b) Second, you will need to join this point dataset to the us_boundaries data. 

```{r}
## Your code here
states <- us_states()

data_by_state <- spatial_join %>%
  st_join(.,states)%>%
  st_transform(2163)

```


### 2c) Then you will want to group by state and sum all the observations in that state and arrange that data from most to least toatl observations per state. 

```{r, echo=T}
## Your code here. 
total_samples_per_state <- data_by_state %>%
  group_by(state_name)%>%
  summarize(total_obs = sum(count))%>%
  mutate(rank=rank(-total_obs))%>%
  arrange(rank)%>%
  slice(1:10)

  
Answer <- view(total_samples_per_state)
  
Answer

```

## 3 Is there a spatial pattern in Secchi disk depth for lakes with at least 200 observations?

```{r}
## Your code here
secchi_200 <- clarity_only %>%
  filter(!is.na(secchi)) %>%
  group_by(lagoslakeid)%>%
  summarize(count=n())%>%
  filter(count>=200)

join_to_spatial <- inner_join(clarity_only, secchi_200)%>%
  filter(!is.na(count),!is.na(secchi))%>%
  group_by(lagoslakeid)%>%
  summarize(mean_secchi=mean(secchi))%>%
  left_join(lake_centers,by='lagoslakeid')%>%
  st_as_sf(coords=c('nhd_long','nhd_lat'), crs=4326)%>%
  arrange(mean_secchi)
  
mapview(join_to_spatial,zcol = 'mean_secchi')

```